"""
ç»„åˆæ•°æ®æ–‡ä»¶ç²¾ç®€å·¥å…·
ç§»é™¤ä¸å¿…è¦çš„æ•°æ®ï¼Œä¿ç•™æ ¸å¿ƒæŠ€æœ¯æŒ‡æ ‡
"""

import pandas as pd
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).resolve().parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

from config import DATA_DIR

def analyze_current_data_structure():
    """åˆ†æå½“å‰æ•°æ®ç»“æ„"""
    print("ğŸ“Š åˆ†æå½“å‰ç»„åˆæ•°æ®ç»“æ„")
    print("=" * 80)
    
    # æŸ¥æ‰¾æœ€æ–°çš„ç»„åˆæ•°æ®æ–‡ä»¶
    csv_files = [f for f in DATA_DIR.glob("*ç»„åˆæ•°æ®*.csv") if not f.name.endswith('.backup.csv') and not f.name.endswith('_streamlined.csv')]
    
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°ç»„åˆæ•°æ®æ–‡ä»¶")
        return None
    
    latest_file = max(csv_files, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ åˆ†ææ–‡ä»¶: {latest_file.name}")
    
    try:
        df = pd.read_csv(latest_file, encoding='utf-8-sig')
        
        print(f"ğŸ“ˆ å½“å‰æ•°æ®ç»“æ„:")
        print(f"   æ•°æ®è¡Œæ•°: {len(df)}")
        print(f"   æ€»åˆ—æ•°: {len(df.columns)}")
        print(f"   æ–‡ä»¶å¤§å°: {latest_file.stat().st_size / 1024:.1f} KB")
        
        # æŒ‰ç±»åˆ«åˆ†æåˆ—
        basic_cols = []
        ma_cols = []
        macd_cols = []
        rsi_cols = []
        bb_cols = []
        fib_retracement_cols = []
        fib_extension_cols = []
        fib_signal_cols = []
        other_cols = []
        
        for col in df.columns:
            if col in ['open_time', 'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æˆäº¤ç¬”æ•°', 'ä¸»åŠ¨ä¹°å…¥é‡', 'ä¸»åŠ¨ä¹°å…¥é¢']:
                basic_cols.append(col)
            elif 'MA' in col and 'MACD' not in col:
                ma_cols.append(col)
            elif 'MACD' in col:
                macd_cols.append(col)
            elif 'RSI' in col:
                rsi_cols.append(col)
            elif 'BB_' in col:
                bb_cols.append(col)
            elif col.startswith('Fib_Ret_'):
                fib_retracement_cols.append(col)
            elif col.startswith('Fib_Ext_'):
                fib_extension_cols.append(col)
            elif col.startswith('Fib_'):
                fib_signal_cols.append(col)
            else:
                other_cols.append(col)
        
        print(f"\nğŸ“‹ åˆ—åˆ†ç±»ç»Ÿè®¡:")
        print(f"   åŸºç¡€æ•°æ® ({len(basic_cols)}): {basic_cols}")
        print(f"   ç§»åŠ¨å¹³å‡ ({len(ma_cols)}): {ma_cols}")
        print(f"   MACD ({len(macd_cols)}): {macd_cols}")
        print(f"   RSI ({len(rsi_cols)}): {rsi_cols}")
        print(f"   å¸ƒæ—å¸¦ ({len(bb_cols)}): {bb_cols}")
        print(f"   æ–æ³¢é‚£å¥‘å›è°ƒ ({len(fib_retracement_cols)}): {fib_retracement_cols}")
        print(f"   æ–æ³¢é‚£å¥‘æ‰©å±• ({len(fib_extension_cols)}): {fib_extension_cols}")
        print(f"   æ–æ³¢é‚£å¥‘ä¿¡å· ({len(fib_signal_cols)}): {fib_signal_cols}")
        print(f"   å…¶ä»–æŒ‡æ ‡ ({len(other_cols)}): {other_cols}")
        
        return latest_file, df
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None, None

def define_streamlined_columns():
    """å®šä¹‰ç²¾ç®€åä¿ç•™çš„åˆ—"""
    print(f"\nğŸ¯ å®šä¹‰ç²¾ç®€æ•°æ®ç»“æ„")
    print("=" * 80)
    
    # æ ¸å¿ƒå¿…éœ€åˆ— (åŸºäºé‡è¦æ€§å’Œå®ç”¨æ€§)
    streamlined_columns = {
        # åŸºç¡€æ•°æ® (å¿…éœ€)
        'basic': [
            'open_time',           # æ—¶é—´æˆ³
            'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·',  # OHLC
            'æˆäº¤é‡'               # æˆäº¤é‡ (ç§»é™¤æˆäº¤é¢ç­‰æ¬¡è¦æ•°æ®)
        ],
        
        # æ ¸å¿ƒç§»åŠ¨å¹³å‡çº¿ (ä¿ç•™æœ€é‡è¦çš„)
        'moving_averages': [
            'MA20',                # çŸ­æœŸMA
            'MA50',                # ä¸­æœŸMA
            # ç§»é™¤: MA_LONG (é•¿æœŸMAï¼Œå¯¹çŸ­çº¿äº¤æ˜“æ„ä¹‰ä¸å¤§)
        ],
        
        # MACD (ä¿ç•™æ ¸å¿ƒ)
        'macd': [
            'MACD',                # MACDä¸»çº¿
            'MACD_Signal',         # ä¿¡å·çº¿
            'MACD_Hist'            # æŸ±çŠ¶å›¾
            # ç§»é™¤: MACD_Longç³»åˆ— (é•¿æœŸMACDå¯¹çŸ­çº¿æ„ä¹‰ä¸å¤§)
        ],
        
        # RSI (ä¿ç•™ä¸»è¦çš„)
        'rsi': [
            'RSI',                 # ä¸»RSI
            # ç§»é™¤: RSI_Secondary, RSI_Long (å¤šé‡RSIé€ æˆå†—ä½™)
        ],
        
        # å¸ƒæ—å¸¦ (ä¿ç•™æ ‡å‡†å¸ƒæ—å¸¦)
        'bollinger': [
            'BB_Upper',            # ä¸Šè½¨
            'BB_Middle',           # ä¸­è½¨
            'BB_Lower'             # ä¸‹è½¨
            # ç§»é™¤: BB_Longç³»åˆ— (é•¿æœŸå¸ƒæ—å¸¦)
        ],
        
        # æ–æ³¢é‚£å¥‘ (ä¿ç•™æœ€å…³é”®çš„)
        'fibonacci_key': [
            'Fib_Ret_0.382',       # 38.2% å…³é”®å›è°ƒä½ â­â­â­â­
            'Fib_Ret_0.500',       # 50% é»„é‡‘åˆ†å‰²ç‚¹ â­â­â­â­â­
            'Fib_Ret_0.618',       # 61.8% é»„é‡‘æ¯”ä¾‹ â­â­â­â­â­
            'Fib_Ext_1.272',       # 127.2% ç¬¬ä¸€ç›®æ ‡ä½
            'Fib_Ext_1.618',       # 161.8% é»„é‡‘æ‰©å±•
            'Fib_Trend',           # è¶‹åŠ¿æ–¹å‘
            'Fib_Signal'           # äº¤æ˜“ä¿¡å·
            # ç§»é™¤: å…¶ä»–æ–æ³¢é‚£å¥‘æ°´å¹³ (23.6%, 78.6%, 100%ç­‰æ¬¡è¦æ°´å¹³)
        ],
        
        # å…¶ä»–æ ¸å¿ƒæŒ‡æ ‡
        'other_core': [
            'ATR',                 # æ³¢åŠ¨ç‡
            'ADX',                 # è¶‹åŠ¿å¼ºåº¦
            'OBV'                  # æˆäº¤é‡æŒ‡æ ‡
            # ç§»é™¤: Stochç³»åˆ—, ATR_Long, ATR_Ratioç­‰
        ]
    }
    
    # åˆå¹¶æ‰€æœ‰ä¿ç•™çš„åˆ—
    all_streamlined = []
    for category, columns in streamlined_columns.items():
        all_streamlined.extend(columns)
    
    print("âœ… ç²¾ç®€åä¿ç•™çš„åˆ—:")
    for category, columns in streamlined_columns.items():
        print(f"   {category} ({len(columns)}): {columns}")
    
    print(f"\nğŸ“Š ç²¾ç®€ç»Ÿè®¡:")
    print(f"   ä¿ç•™æ€»åˆ—æ•°: {len(all_streamlined)}")
    print(f"   é¢„è®¡å‡å°‘: ~{51 - len(all_streamlined)}åˆ—")
    
    return all_streamlined

def create_streamlined_file(original_file, df, streamlined_columns):
    """åˆ›å»ºç²¾ç®€çš„ç»„åˆæ•°æ®æ–‡ä»¶"""
    print(f"\nğŸ”§ åˆ›å»ºç²¾ç®€æ•°æ®æ–‡ä»¶")
    print("=" * 80)
    
    try:
        # æ£€æŸ¥å“ªäº›åˆ—å®é™…å­˜åœ¨
        available_columns = [col for col in streamlined_columns if col in df.columns]
        missing_columns = [col for col in streamlined_columns if col not in df.columns]
        
        if missing_columns:
            print(f"âš ï¸ ç¼ºå¤±åˆ—: {missing_columns}")
        
        print(f"âœ… å¯ç”¨åˆ—: {len(available_columns)}/{len(streamlined_columns)}")
        
        # åˆ›å»ºç²¾ç®€æ•°æ®æ¡†
        streamlined_df = df[available_columns].copy()
        
        # ä¼˜åŒ–æ•°æ®ç±»å‹
        numeric_columns = streamlined_df.select_dtypes(include=['float64']).columns
        if len(numeric_columns) > 0:
            streamlined_df[numeric_columns] = streamlined_df[numeric_columns].astype('float32')
        
        # ç”Ÿæˆç²¾ç®€æ–‡ä»¶å
        original_name = original_file.stem
        streamlined_filename = f"{original_name}_streamlined.csv"
        streamlined_path = original_file.parent / streamlined_filename
        
        # ä¿å­˜ç²¾ç®€æ–‡ä»¶
        streamlined_df.to_csv(streamlined_path, encoding='utf-8-sig', index=False)
        
        # è®¡ç®—æ–‡ä»¶å¤§å°å˜åŒ–
        original_size = original_file.stat().st_size / 1024
        streamlined_size = streamlined_path.stat().st_size / 1024
        size_reduction = (original_size - streamlined_size) / original_size * 100
        
        print(f"âœ… ç²¾ç®€æ–‡ä»¶åˆ›å»ºæˆåŠŸ:")
        print(f"   æ–‡ä»¶å: {streamlined_filename}")
        print(f"   åˆ—æ•°: {len(df.columns)} â†’ {len(streamlined_df.columns)} (å‡å°‘{len(df.columns) - len(streamlined_df.columns)}åˆ—)")
        print(f"   æ–‡ä»¶å¤§å°: {original_size:.1f}KB â†’ {streamlined_size:.1f}KB")
        print(f"   ç©ºé—´èŠ‚çœ: {size_reduction:.1f}%")
        
        return streamlined_path, streamlined_df
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºç²¾ç®€æ–‡ä»¶å¤±è´¥: {e}")
        return None, None

def validate_streamlined_data(streamlined_df):
    """éªŒè¯ç²¾ç®€æ•°æ®çš„å®Œæ•´æ€§"""
    print(f"\nğŸ” éªŒè¯ç²¾ç®€æ•°æ®å®Œæ•´æ€§")
    print("=" * 80)
    
    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    total_rows = len(streamlined_df)
    
    print("ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
    
    # æ£€æŸ¥åŸºç¡€æ•°æ®
    basic_cols = ['æ”¶ç›˜ä»·', 'æˆäº¤é‡', 'MA20', 'RSI']
    for col in basic_cols:
        if col in streamlined_df.columns:
            valid_count = streamlined_df[col].notna().sum()
            print(f"   {col}: {valid_count}/{total_rows} ({valid_count/total_rows*100:.1f}%)")
    
    # æ£€æŸ¥æ–æ³¢é‚£å¥‘å…³é”®æ°´å¹³
    fib_key_cols = ['Fib_Ret_0.382', 'Fib_Ret_0.500', 'Fib_Ret_0.618']
    print(f"\nğŸ”¢ æ–æ³¢é‚£å¥‘å…³é”®æ°´å¹³:")
    for col in fib_key_cols:
        if col in streamlined_df.columns:
            valid_count = streamlined_df[col].notna().sum()
            latest_value = streamlined_df[col].dropna().iloc[-1] if valid_count > 0 else 'N/A'
            print(f"   {col}: {valid_count}/{total_rows} ({valid_count/total_rows*100:.1f}%) - æœ€æ–°: ${latest_value:.2f}" if latest_value != 'N/A' else f"   {col}: æ— æ•°æ®")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®é¢„è§ˆ
    print(f"\nğŸ“‹ ç²¾ç®€æ•°æ®é¢„è§ˆ (æœ€æ–°5è¡Œ):")
    preview_cols = ['æ”¶ç›˜ä»·', 'MA20', 'RSI', 'Fib_Ret_0.500', 'Fib_Signal']
    available_preview_cols = [col for col in preview_cols if col in streamlined_df.columns]
    
    if available_preview_cols:
        preview = streamlined_df[available_preview_cols].tail(5)
        print(preview.to_string(float_format='%.2f'))

def create_streamlined_comparison():
    """åˆ›å»ºç²¾ç®€å‰åå¯¹æ¯”"""
    print(f"\nğŸ“Š ç²¾ç®€æ•ˆæœå¯¹æ¯”")
    print("=" * 80)
    
    # å¯¹æ¯”è¡¨æ ¼
    comparison_data = {
        'é¡¹ç›®': ['æ€»åˆ—æ•°', 'åŸºç¡€æ•°æ®', 'æŠ€æœ¯æŒ‡æ ‡', 'æ–æ³¢é‚£å¥‘', 'æ–‡ä»¶å¤§å°', 'é€‚ç”¨åœºæ™¯'],
        'åŸå§‹æ–‡ä»¶': ['51åˆ—', '10åˆ—', '22åˆ—', '19åˆ—', '~90KB', 'å®Œæ•´åˆ†æ'],
        'ç²¾ç®€æ–‡ä»¶': ['~25åˆ—', '6åˆ—', '12åˆ—', '7åˆ—', '~45KB', 'æ ¸å¿ƒäº¤æ˜“'],
        'å‡å°‘æ¯”ä¾‹': ['~51%', '40%', '45%', '63%', '50%', 'èšç„¦æ ¸å¿ƒ']
    }
    
    comparison_df = pd.DataFrame(comparison_data)
    print(comparison_df.to_string(index=False))
    
    print(f"\nâœ… ç²¾ç®€ä¼˜åŠ¿:")
    print("   1. æ–‡ä»¶å¤§å°å‡å°‘50%ï¼Œä¸Šä¼ æ›´å¿«")
    print("   2. æ•°æ®æ›´èšç„¦ï¼ŒDeepSeekåˆ†ææ›´ç²¾å‡†")
    print("   3. ä¿ç•™æœ€å…³é”®çš„æ–æ³¢é‚£å¥‘æ°´å¹³")
    print("   4. ç§»é™¤å†—ä½™æŒ‡æ ‡ï¼Œçªå‡ºæ ¸å¿ƒä¿¡å·")
    print("   5. é€‚åˆå¿«é€Ÿå†³ç­–å’ŒçŸ­çº¿äº¤æ˜“")

def main():
    """ä¸»å‡½æ•°"""
    print("BTCUSDT ç»„åˆæ•°æ®ç²¾ç®€å·¥å…·")
    print("=" * 80)
    print("ç›®æ ‡: ä¿ç•™æ ¸å¿ƒæŠ€æœ¯æŒ‡æ ‡ï¼Œç§»é™¤ä¸å¿…è¦æ•°æ®")
    print("=" * 80)
    
    # 1. åˆ†æå½“å‰æ•°æ®ç»“æ„
    original_file, df = analyze_current_data_structure()
    
    if original_file is None:
        return
    
    # 2. å®šä¹‰ç²¾ç®€åˆ—
    streamlined_columns = define_streamlined_columns()
    
    # 3. åˆ›å»ºç²¾ç®€æ–‡ä»¶
    streamlined_path, streamlined_df = create_streamlined_file(original_file, df, streamlined_columns)
    
    if streamlined_path is None:
        return
    
    # 4. éªŒè¯ç²¾ç®€æ•°æ®
    validate_streamlined_data(streamlined_df)
    
    # 5. æ˜¾ç¤ºå¯¹æ¯”
    create_streamlined_comparison()
    
    print(f"\n" + "=" * 80)
    print("ğŸ‰ æ•°æ®ç²¾ç®€å®Œæˆ!")
    print(f"âœ… ç²¾ç®€æ–‡ä»¶: {streamlined_path.name}")
    print("âœ… ä¿ç•™äº†æœ€æ ¸å¿ƒçš„æŠ€æœ¯æŒ‡æ ‡")
    print("âœ… é‡ç‚¹ä¿ç•™æ–æ³¢é‚£å¥‘å…³é”®æ°´å¹³: 38.2%, 50%, 61.8%")
    print("âœ… æ–‡ä»¶å¤§å°å‡å°‘çº¦50%")
    print("\nğŸ’¡ å»ºè®®:")
    print("   - ä½¿ç”¨ç²¾ç®€æ–‡ä»¶å‘é€ç»™DeepSeek AI")
    print("   - é€‚åˆçŸ­çº¿å’Œæ—¥å†…äº¤æ˜“åˆ†æ")
    print("   - èšç„¦æœ€é‡è¦çš„æŠ€æœ¯ä¿¡å·")

if __name__ == "__main__":
    main()
