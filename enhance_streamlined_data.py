"""
å¢å¼ºç²¾ç®€æ•°æ®æ–‡ä»¶
åœ¨ä¿æŒç²¾ç®€çš„åŒæ—¶ï¼Œå¢åŠ ä¸€äº›é‡è¦çš„æŠ€æœ¯æŒ‡æ ‡
"""

import pandas as pd
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).resolve().parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

from config import DATA_DIR

def analyze_missing_important_indicators():
    """åˆ†æå¯èƒ½é—æ¼çš„é‡è¦æŒ‡æ ‡"""
    print("ğŸ” åˆ†æå¯èƒ½é—æ¼çš„é‡è¦æŠ€æœ¯æŒ‡æ ‡")
    print("=" * 80)
    
    # æŸ¥æ‰¾åŸå§‹æ–‡ä»¶å’Œå½“å‰ç²¾ç®€æ–‡ä»¶
    original_files = [f for f in DATA_DIR.glob("*ç»„åˆæ•°æ®*.csv") if not f.name.endswith('_streamlined.csv') and not f.name.endswith('.backup.csv')]
    
    if not original_files:
        print("âŒ æœªæ‰¾åˆ°åŸå§‹æ–‡ä»¶")
        return None
    
    latest_original = max(original_files, key=lambda x: x.stat().st_mtime)
    
    try:
        df_original = pd.read_csv(latest_original, encoding='utf-8-sig')
        
        # å½“å‰ç²¾ç®€ç‰ˆæœ¬åŒ…å«çš„åˆ—
        current_streamlined = [
            'open_time', 'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·', 'æˆäº¤é‡',
            'MA20', 'MA50', 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI',
            'BB_Upper', 'BB_Middle', 'BB_Lower', 'Fib_Ret_0.382', 'Fib_Ret_0.500', 'Fib_Ret_0.618',
            'Fib_Ext_1.272', 'Fib_Ext_1.618', 'Fib_Trend', 'Fib_Signal', 'ATR', 'ADX', 'OBV'
        ]
        
        # åˆ†æåŸå§‹æ–‡ä»¶ä¸­çš„æ‰€æœ‰åˆ—
        all_columns = list(df_original.columns)
        missing_columns = [col for col in all_columns if col not in current_streamlined]
        
        print(f"ğŸ“Š åŸå§‹æ–‡ä»¶åˆ†æ: {latest_original.name}")
        print(f"   æ€»åˆ—æ•°: {len(all_columns)}")
        print(f"   å½“å‰ç²¾ç®€ç‰ˆåˆ—æ•°: {len(current_streamlined)}")
        print(f"   æœªåŒ…å«çš„åˆ—æ•°: {len(missing_columns)}")
        
        # æŒ‰é‡è¦æ€§åˆ†ç±»æœªåŒ…å«çš„åˆ—
        important_missing = []
        moderate_missing = []
        less_important = []
        
        for col in missing_columns:
            if col in ['æˆäº¤é¢', 'Stoch_SlowK', 'Stoch_SlowD', 'MA_LONG', 'RSI_Long']:
                important_missing.append(col)
            elif col in ['Fib_Ret_0.236', 'Fib_Ret_0.786', 'MACD_Long', 'BB_Long_Upper', 'ATR_Long']:
                moderate_missing.append(col)
            else:
                less_important.append(col)
        
        print(f"\nğŸ“ˆ é‡è¦æ€§åˆ†æ:")
        print(f"   ğŸ”´ é‡è¦ä½†ç¼ºå¤±: {important_missing}")
        print(f"   ğŸŸ¡ ä¸­ç­‰é‡è¦: {moderate_missing}")
        print(f"   ğŸŸ¢ æ¬¡è¦æŒ‡æ ‡: {less_important}")
        
        return df_original, current_streamlined, important_missing, moderate_missing
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None, None, None, None

def define_enhanced_streamlined_columns():
    """å®šä¹‰å¢å¼ºç‰ˆç²¾ç®€åˆ—"""
    print(f"\nğŸ¯ å®šä¹‰å¢å¼ºç‰ˆç²¾ç®€æ•°æ®ç»“æ„")
    print("=" * 80)
    
    enhanced_columns = {
        # åŸºç¡€æ•°æ® (å¢åŠ æˆäº¤é¢)
        'basic': [
            'open_time',           # æ—¶é—´æˆ³
            'å¼€ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æ”¶ç›˜ä»·',  # OHLC
            'æˆäº¤é‡', 'æˆäº¤é¢'      # æˆäº¤é‡å’Œæˆäº¤é¢ (æˆäº¤é¢å¾ˆé‡è¦)
        ],
        
        # ç§»åŠ¨å¹³å‡çº¿ (å¢åŠ é•¿æœŸMA)
        'moving_averages': [
            'MA20',                # çŸ­æœŸMA
            'MA50',                # ä¸­æœŸMA
            'MA_LONG'              # é•¿æœŸMA (é‡è¦çš„è¶‹åŠ¿æŒ‡æ ‡)
        ],
        
        # MACD (ä¿æŒæ ¸å¿ƒï¼Œå¢åŠ é•¿æœŸMACD)
        'macd': [
            'MACD',                # MACDä¸»çº¿
            'MACD_Signal',         # ä¿¡å·çº¿
            'MACD_Hist',           # æŸ±çŠ¶å›¾
            'MACD_Long'            # é•¿æœŸMACD (è¶‹åŠ¿ç¡®è®¤)
        ],
        
        # RSI (å¢åŠ é•¿æœŸRSI)
        'rsi': [
            'RSI',                 # ä¸»RSI
            'RSI_Long'             # é•¿æœŸRSI (è¶‹åŠ¿è¿‡æ»¤)
        ],
        
        # å¸ƒæ—å¸¦ (ä¿ç•™æ ‡å‡†ï¼Œå¢åŠ é•¿æœŸå¸ƒæ—å¸¦ä¸Šè½¨)
        'bollinger': [
            'BB_Upper',            # ä¸Šè½¨
            'BB_Middle',           # ä¸­è½¨
            'BB_Lower',            # ä¸‹è½¨
            'BB_Long_Upper'        # é•¿æœŸå¸ƒæ—å¸¦ä¸Šè½¨ (é‡è¦é˜»åŠ›)
        ],
        
        # éšæœºæŒ‡æ ‡ (é‡æ–°åŠ å…¥ï¼Œå¾ˆé‡è¦çš„è¶…ä¹°è¶…å–æŒ‡æ ‡)
        'stochastic': [
            'Stoch_SlowK',         # éšæœºæŒ‡æ ‡Kçº¿
            'Stoch_SlowD'          # éšæœºæŒ‡æ ‡Dçº¿
        ],
        
        # æ–æ³¢é‚£å¥‘ (å¢åŠ æ›´å¤šå…³é”®æ°´å¹³)
        'fibonacci_enhanced': [
            'Fib_Ret_0.236',       # 23.6% æµ…å›è°ƒ
            'Fib_Ret_0.382',       # 38.2% å…³é”®å›è°ƒä½ â­â­â­â­
            'Fib_Ret_0.500',       # 50% é»„é‡‘åˆ†å‰²ç‚¹ â­â­â­â­â­
            'Fib_Ret_0.618',       # 61.8% é»„é‡‘æ¯”ä¾‹ â­â­â­â­â­
            'Fib_Ret_0.786',       # 78.6% æ·±åº¦å›è°ƒ
            'Fib_Ext_1.272',       # 127.2% ç¬¬ä¸€ç›®æ ‡ä½
            'Fib_Ext_1.414',       # 141.4% æ‰©å±•ä½ (ç§»é™¤1.618)
            'Fib_Trend',           # è¶‹åŠ¿æ–¹å‘
            'Fib_Signal',          # äº¤æ˜“ä¿¡å·
            'Fib_Support_Level',   # æ”¯æ’‘ä½
            'Fib_Resistance_Level' # é˜»åŠ›ä½
        ],
        
        # å…¶ä»–æ ¸å¿ƒæŒ‡æ ‡ (å¢åŠ ATRé•¿æœŸ)
        'other_core': [
            'ATR',                 # çŸ­æœŸæ³¢åŠ¨ç‡
            'ATR_Long',            # é•¿æœŸæ³¢åŠ¨ç‡ (é‡è¦çš„æ³¢åŠ¨ç‡å¯¹æ¯”)
            'ADX',                 # è¶‹åŠ¿å¼ºåº¦
            'OBV'                  # æˆäº¤é‡æŒ‡æ ‡
        ]
    }
    
    # åˆå¹¶æ‰€æœ‰ä¿ç•™çš„åˆ—
    all_enhanced = []
    for category, columns in enhanced_columns.items():
        all_enhanced.extend(columns)
    
    print("âœ… å¢å¼ºç‰ˆç²¾ç®€åä¿ç•™çš„åˆ—:")
    for category, columns in enhanced_columns.items():
        print(f"   {category} ({len(columns)}): {columns}")
    
    print(f"\nğŸ“Š å¢å¼ºç‰ˆç»Ÿè®¡:")
    print(f"   ä¿ç•™æ€»åˆ—æ•°: {len(all_enhanced)}")
    print(f"   ç›¸æ¯”å½“å‰ç‰ˆæœ¬å¢åŠ : {len(all_enhanced) - 25}åˆ—")
    print(f"   ç›¸æ¯”åŸå§‹ç‰ˆæœ¬å‡å°‘: ~{54 - len(all_enhanced)}åˆ—")
    
    return all_enhanced

def create_enhanced_streamlined_files():
    """åˆ›å»ºå¢å¼ºç‰ˆç²¾ç®€æ–‡ä»¶"""
    print(f"\nğŸ”§ åˆ›å»ºå¢å¼ºç‰ˆç²¾ç®€æ•°æ®æ–‡ä»¶")
    print("=" * 80)
    
    # å®šä¹‰å¢å¼ºç‰ˆåˆ—
    enhanced_columns = define_enhanced_streamlined_columns()
    
    # æŸ¥æ‰¾åŸå§‹æ–‡ä»¶
    original_files = [f for f in DATA_DIR.glob("*ç»„åˆæ•°æ®*.csv") if not f.name.endswith('_streamlined.csv') and not f.name.endswith('.backup.csv')]
    
    results = []
    
    for original_file in original_files:
        print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {original_file.name}")
        
        try:
            df = pd.read_csv(original_file, encoding='utf-8-sig')
            
            # æ£€æŸ¥å“ªäº›åˆ—å®é™…å­˜åœ¨
            available_columns = [col for col in enhanced_columns if col in df.columns]
            missing_columns = [col for col in enhanced_columns if col not in df.columns]
            
            if missing_columns:
                print(f"   âš ï¸ ç¼ºå¤±åˆ—: {missing_columns}")
            
            print(f"   âœ… å¯ç”¨åˆ—: {len(available_columns)}/{len(enhanced_columns)}")
            
            # åˆ›å»ºå¢å¼ºç‰ˆç²¾ç®€æ•°æ®æ¡†
            enhanced_df = df[available_columns].copy()
            
            # ä¼˜åŒ–æ•°æ®ç±»å‹
            numeric_columns = enhanced_df.select_dtypes(include=['float64']).columns
            if len(numeric_columns) > 0:
                enhanced_df[numeric_columns] = enhanced_df[numeric_columns].astype('float32')
            
            # ç”Ÿæˆå¢å¼ºç‰ˆæ–‡ä»¶å
            original_name = original_file.stem
            enhanced_filename = f"{original_name}_enhanced.csv"
            enhanced_path = original_file.parent / enhanced_filename
            
            # ä¿å­˜å¢å¼ºç‰ˆæ–‡ä»¶
            enhanced_df.to_csv(enhanced_path, encoding='utf-8-sig', index=False)
            
            # è®¡ç®—æ–‡ä»¶å¤§å°å˜åŒ–
            original_size = original_file.stat().st_size / 1024
            enhanced_size = enhanced_path.stat().st_size / 1024
            size_reduction = (original_size - enhanced_size) / original_size * 100
            
            print(f"   âœ… å¢å¼ºç‰ˆæ–‡ä»¶åˆ›å»ºæˆåŠŸ:")
            print(f"      æ–‡ä»¶å: {enhanced_filename}")
            print(f"      åˆ—æ•°: {len(df.columns)} â†’ {len(enhanced_df.columns)} (å‡å°‘{len(df.columns) - len(enhanced_df.columns)}åˆ—)")
            print(f"      æ–‡ä»¶å¤§å°: {original_size:.1f}KB â†’ {enhanced_size:.1f}KB")
            print(f"      ç©ºé—´èŠ‚çœ: {size_reduction:.1f}%")
            
            results.append({
                'file': enhanced_path,
                'df': enhanced_df,
                'original_cols': len(df.columns),
                'enhanced_cols': len(enhanced_df.columns),
                'size_reduction': size_reduction
            })
            
        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
    
    return results

def validate_enhanced_files(results):
    """éªŒè¯å¢å¼ºç‰ˆæ–‡ä»¶"""
    print(f"\nğŸ” éªŒè¯å¢å¼ºç‰ˆæ–‡ä»¶")
    print("=" * 80)
    
    for result in results:
        file_path = result['file']
        df = result['df']
        
        print(f"\nğŸ“Š éªŒè¯æ–‡ä»¶: {file_path.name}")
        print("-" * 60)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"   æ•°æ®è¡Œæ•°: {len(df)}")
        print(f"   åˆ—æ•°: {len(df.columns)}")
        print(f"   æ–‡ä»¶å¤§å°: {file_path.stat().st_size / 1024:.1f} KB")
        
        # æ£€æŸ¥æ ¸å¿ƒæŒ‡æ ‡å®Œæ•´æ€§
        core_indicators = ['æ”¶ç›˜ä»·', 'MA20', 'MA50', 'RSI', 'MACD', 'ATR', 'Stoch_SlowK']
        missing_core = [col for col in core_indicators if col not in df.columns]
        if missing_core:
            print(f"   âš ï¸ ç¼ºå¤±æ ¸å¿ƒæŒ‡æ ‡: {missing_core}")
        else:
            print(f"   âœ… æ ¸å¿ƒæŠ€æœ¯æŒ‡æ ‡å®Œæ•´")
        
        # æ£€æŸ¥æ–æ³¢é‚£å¥‘æ°´å¹³
        fib_levels = ['Fib_Ret_0.382', 'Fib_Ret_0.500', 'Fib_Ret_0.618', 'Fib_Ret_0.236', 'Fib_Ret_0.786']
        fib_present = [col for col in fib_levels if col in df.columns]
        print(f"   ğŸ”¢ æ–æ³¢é‚£å¥‘æ°´å¹³: {len(fib_present)}/5")
        
        # æ˜¾ç¤ºæœ€æ–°æ•°æ®é¢„è§ˆ
        preview_cols = ['æ”¶ç›˜ä»·', 'MA20', 'RSI', 'Stoch_SlowK', 'Fib_Ret_0.500', 'Fib_Signal']
        available_preview = [col for col in preview_cols if col in df.columns]
        
        if available_preview:
            print(f"   ğŸ“‹ æœ€æ–°æ•°æ®é¢„è§ˆ:")
            preview = df[available_preview].tail(3)
            print(preview.to_string(float_format='%.2f', index=False))

def create_comparison_table(results):
    """åˆ›å»ºç‰ˆæœ¬å¯¹æ¯”è¡¨"""
    print(f"\nğŸ“Š ç‰ˆæœ¬å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    comparison_data = {
        'ç‰ˆæœ¬': ['åŸå§‹ç‰ˆæœ¬', 'ç²¾ç®€ç‰ˆæœ¬', 'å¢å¼ºç‰ˆæœ¬'],
        'åˆ—æ•°': ['51-54', '25', f'{results[0]["enhanced_cols"] if results else "~35"}'],
        'æ–‡ä»¶å¤§å°': ['120-140KB', '60-75KB', '85-105KB'],
        'ç©ºé—´èŠ‚çœ': ['0%', '~50%', '~25%'],
        'é€‚ç”¨åœºæ™¯': ['å®Œæ•´åˆ†æ', 'å¿«é€Ÿåˆ†æ', 'å¹³è¡¡åˆ†æ'],
        'æ¨èç”¨é€”': ['æ·±åº¦ç ”ç©¶', 'AIå¿«é€Ÿåˆ†æ', 'AIå…¨é¢åˆ†æ']
    }
    
    comparison_df = pd.DataFrame(comparison_data)
    print(comparison_df.to_string(index=False))
    
    print(f"\nâœ… å¢å¼ºç‰ˆæœ¬ä¼˜åŠ¿:")
    print("   1. ä¿ç•™äº†é‡è¦çš„é•¿æœŸæŒ‡æ ‡ (MA_LONG, RSI_Long)")
    print("   2. é‡æ–°åŠ å…¥éšæœºæŒ‡æ ‡ (Stoch_SlowK/D)")
    print("   3. å¢åŠ æˆäº¤é¢æ•°æ®")
    print("   4. æ‰©å±•æ–æ³¢é‚£å¥‘æ°´å¹³ (23.6%, 78.6%)")
    print("   5. å¢åŠ æ–æ³¢é‚£å¥‘æ”¯æ’‘é˜»åŠ›ä½")
    print("   6. ä¿ç•™é•¿æœŸATRå¯¹æ¯”")
    print("   7. å¹³è¡¡äº†ç²¾ç®€åº¦å’Œå®Œæ•´æ€§")

def main():
    """ä¸»å‡½æ•°"""
    print("BTCUSDT å¢å¼ºç‰ˆç²¾ç®€æ•°æ®å·¥å…·")
    print("=" * 80)
    print("ç›®æ ‡: åœ¨ä¿æŒç²¾ç®€çš„åŒæ—¶ï¼Œå¢åŠ é‡è¦çš„æŠ€æœ¯æŒ‡æ ‡")
    print("=" * 80)
    
    # 1. åˆ†æé—æ¼çš„é‡è¦æŒ‡æ ‡
    analysis_result = analyze_missing_important_indicators()
    
    if analysis_result[0] is None:
        return
    
    # 2. åˆ›å»ºå¢å¼ºç‰ˆç²¾ç®€æ–‡ä»¶
    results = create_enhanced_streamlined_files()
    
    if not results:
        print("âŒ æœªèƒ½åˆ›å»ºå¢å¼ºç‰ˆæ–‡ä»¶")
        return
    
    # 3. éªŒè¯å¢å¼ºç‰ˆæ–‡ä»¶
    validate_enhanced_files(results)
    
    # 4. åˆ›å»ºå¯¹æ¯”è¡¨
    create_comparison_table(results)
    
    print(f"\n" + "=" * 80)
    print("ğŸ‰ å¢å¼ºç‰ˆç²¾ç®€æ•°æ®åˆ›å»ºå®Œæˆ!")
    print(f"âœ… å¢å¼ºç‰ˆæ–‡ä»¶åˆ—æ•°: ~{results[0]['enhanced_cols']}åˆ—")
    print("âœ… ä¿ç•™äº†æ‰€æœ‰æ ¸å¿ƒæŠ€æœ¯æŒ‡æ ‡")
    print("âœ… é‡æ–°åŠ å…¥é‡è¦çš„è¾…åŠ©æŒ‡æ ‡")
    print("âœ… æ‰©å±•äº†æ–æ³¢é‚£å¥‘åˆ†æèƒ½åŠ›")
    print("âœ… å¹³è¡¡äº†æ–‡ä»¶å¤§å°å’Œåˆ†æå®Œæ•´æ€§")
    
    print(f"\nğŸ“ æ¨èä½¿ç”¨çš„å¢å¼ºç‰ˆæ–‡ä»¶:")
    for result in results:
        print(f"   â€¢ {result['file'].name}")
    
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("   - å‘é€ç»™DeepSeek AIè¿›è¡Œå…¨é¢æŠ€æœ¯åˆ†æ")
    print("   - é€‚åˆä¸­çŸ­æœŸäº¤æ˜“ç­–ç•¥åˆ¶å®š")
    print("   - åŒ…å«è¶³å¤Ÿçš„æŒ‡æ ‡è¿›è¡Œå¤šé‡ç¡®è®¤")
    print("   - æ–‡ä»¶å¤§å°é€‚ä¸­ï¼Œä¼ è¾“æ•ˆç‡è‰¯å¥½")

if __name__ == "__main__":
    main()
