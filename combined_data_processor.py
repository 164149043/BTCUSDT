"""
ç»„åˆæ•°æ®å¤„ç†æ¨¡å—
åŠŸèƒ½ï¼šåˆå¹¶åŸå§‹æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œç”ŸæˆåŒ…å«å®Œæ•´ä¿¡æ¯çš„CSVæ–‡ä»¶
è¾“å‡ºï¼šåŒ…å«æ—¥çº¿åŸå§‹æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡çš„åˆå¹¶æ•°æ®é›†
"""

import pandas as pd
import os
import sys
from pathlib import Path
from datetime import datetime
from config import DATA_DIR, RAW_DATA_FILENAME, INDICATORS_FILENAME, COMBINED_FILENAME, SYMBOL, get_filenames

def combine_data(raw_filename=None, indicators_filename=None, combined_filename=None, timeframe_name=None):
    """
    ä¸»å‡½æ•°ï¼šåˆå¹¶åŸå§‹æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®
    å‚æ•°:
        raw_filename: åŸå§‹æ•°æ®æ–‡ä»¶å
        indicators_filename: æŒ‡æ ‡æ•°æ®æ–‡ä»¶å
        combined_filename: ç»„åˆæ•°æ®æ–‡ä»¶å
        timeframe_name: æ—¶é—´å‘¨æœŸåç§°
    è¿”å›:
        Path: åˆå¹¶åæ–‡ä»¶çš„è·¯å¾„å¯¹è±¡
        None: å¦‚æœåˆå¹¶å¤±è´¥
    """
    print("\n" + "=" * 50)
    print(f"å¼€å§‹åˆå¹¶åŸå§‹æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ® - {timeframe_name or 'æ—¥çº¿'}")
    print("=" * 50)

    # 1. ç¡®å®šæ–‡ä»¶è·¯å¾„
    raw_path = DATA_DIR / (raw_filename or RAW_DATA_FILENAME)
    if not raw_path.exists():
        print(f"âŒ é”™è¯¯: åŸå§‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ - {raw_path}")
        return None

    try:
        raw_df = pd.read_csv(raw_path, encoding='utf-8-sig')
        print(f"âœ… æˆåŠŸåŠ è½½åŸå§‹æ•°æ®, å…± {len(raw_df)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ åŠ è½½åŸå§‹æ•°æ®å¤±è´¥: {e}")
        return None

    # 2. åŠ è½½æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    indicators_path = DATA_DIR / (indicators_filename or INDICATORS_FILENAME)
    if not indicators_path.exists():
        print(f"âŒ é”™è¯¯: æŠ€æœ¯æŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨ - {indicators_path}")
        return None

    try:
        indicators_df = pd.read_csv(indicators_path, encoding='utf-8-sig')
        print(f"âœ… æˆåŠŸåŠ è½½æŠ€æœ¯æŒ‡æ ‡æ•°æ®, å…± {len(indicators_df)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ åŠ è½½æŠ€æœ¯æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
        return None

    # 3. æ•°æ®é¢„å¤„ç†
    print("ğŸ”„ æ•°æ®é¢„å¤„ç†ä¸­...")

    # æŸ¥æ‰¾æ—¶é—´åˆ—ï¼ˆå…¼å®¹ä¸åŒåˆ—åï¼‰
    time_col = None
    for col in ['open_time', 'æ—¥æœŸ', 'æ—¶é—´', 'timestamp']:
        if col in raw_df.columns and col in indicators_df.columns:
            time_col = col
            break

    if not time_col:
        print("âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ°å…±åŒçš„æ—¶é—´åˆ—")
        return None

    # ç»Ÿä¸€æ—¶é—´æ ¼å¼
    for df in [raw_df, indicators_df]:
        df[time_col] = pd.to_datetime(df[time_col])
        df.sort_values(time_col, inplace=True)
        df.reset_index(drop=True, inplace=True)

    # 4. åˆå¹¶æ•°æ®
    print("ğŸ”€ åˆå¹¶æ•°æ®ä¸­...")

    # è¯†åˆ«é‡å¤åˆ—ï¼ˆé™¤äº†æ—¶é—´åˆ—ï¼‰
    duplicate_cols = [col for col in indicators_df.columns
                     if col in raw_df.columns and col != time_col]

    if duplicate_cols:
        print(f"â– ç§»é™¤é‡å¤åˆ—: {', '.join(duplicate_cols)}")
        indicators_df = indicators_df.drop(columns=duplicate_cols)

    # æ‰§è¡Œåˆå¹¶ï¼ˆå†…è¿æ¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼‰
    try:
        combined_df = pd.merge(
            raw_df,
            indicators_df,
            on=time_col,
            how='inner',
            validate='one_to_one'
        )

        # å®šä¹‰è¦ç§»é™¤çš„åˆ—
        columns_to_remove = [
            'è®¡ç®—æ—¶é—´',
            'MA_Signal',
            'MACD_Signal_Analysis',
            'RSI_Signal',
            'BB_Signal',
            'Stoch_Signal',
            'ç»¼åˆä¿¡å·'
        ]

        # ç§»é™¤ä¸éœ€è¦çš„åˆ—ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
        existing_columns_to_remove = [col for col in columns_to_remove if col in combined_df.columns]
        if existing_columns_to_remove:
            combined_df = combined_df.drop(columns=existing_columns_to_remove)
            print(f"ğŸ—‘ï¸ å·²ç§»é™¤åˆ—: {', '.join(existing_columns_to_remove)}")

        # æŒ‰æ—¶é—´æ’åº
        combined_df.sort_values(time_col, ascending=True, inplace=True)
        combined_df.reset_index(drop=True, inplace=True)
    except Exception as e:
        print(f"âŒ æ•°æ®åˆå¹¶å¤±è´¥: {e}")
        return None

    # 5. ä¿å­˜ç»“æœ
    combined_path = DATA_DIR / (combined_filename or COMBINED_FILENAME)

    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        combined_path.parent.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜ä¸ºCSVï¼ˆå…¼å®¹ä¸­æ–‡Excelï¼‰
        combined_df.to_csv(combined_path, encoding='utf-8-sig', index=False)

        print(f"âœ… æ•°æ®åˆå¹¶å®Œæˆ! æ–‡ä»¶ä¿å­˜è‡³: {combined_path}")
        print(f"ğŸ“Š åˆå¹¶åæ•°æ®ç»´åº¦: {len(combined_df)} è¡Œ Ã— {len(combined_df.columns)} åˆ—")

        return combined_path
    except Exception as e:
        print(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
        return None

def display_combined_data_preview(file_path, num_rows=5):
    """
    æ˜¾ç¤ºåˆå¹¶æ•°æ®çš„é¢„è§ˆä¿¡æ¯
    å‚æ•°:
        file_path (Path): æ•°æ®æ–‡ä»¶è·¯å¾„
        num_rows (int): æ˜¾ç¤ºçš„è¡Œæ•°ï¼ˆé¦–å°¾å„æ˜¾ç¤ºnum_rowsè¡Œï¼‰
    """
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')

        print("\n" + "=" * 50)
        print(f"åˆå¹¶æ•°æ®é¢„è§ˆ ({file_path.name})")
        print("=" * 50)

        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        print(f"â— æ—¶é—´èŒƒå›´: {df.iloc[0, 0]} è‡³ {df.iloc[-1, 0]}")
        print(f"â— æ€»è®°å½•æ•°: {len(df)}")
        print(f"â— æ•°æ®åˆ—æ•°: {len(df.columns)}")

        # é€‰æ‹©å…³é”®åˆ—æ˜¾ç¤º
        key_columns = [
            col for col in [
                'open_time', 'æ—¥æœŸ', 'æ—¶é—´', 'timestamp',
                'å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'æœ€é«˜ä»·', 'æœ€ä½ä»·', 'æˆäº¤é‡',
                'MA20', 'MA50', 'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower'
            ] if col in df.columns
        ]

        # æ˜¾ç¤ºé¦–å°¾æ•°æ®
        if len(df) > num_rows * 2:
            preview = pd.concat([df.head(num_rows), df.tail(num_rows)])
            print(f"\nã€é¦–{num_rows}è¡Œ + å°¾{num_rows}è¡Œã€‘:")
        else:
            preview = df
            print("\nã€å…¨éƒ¨æ•°æ®ã€‘:")

        print(preview[key_columns].to_string(index=False))

        # æ˜¾ç¤ºåˆ—åæ¸…å•
        print("\nã€å…¨éƒ¨åˆ—åã€‘:")
        print(", ".join(df.columns))

    except Exception as e:
        print(f"âŒ æ•°æ®é¢„è§ˆå¤±è´¥: {e}")

def get_latest_combined_path():
    """è·å–æœ€æ–°çš„ç»„åˆæ•°æ®æ–‡ä»¶è·¯å¾„"""
    combined_path = DATA_DIR / COMBINED_FILENAME
    return combined_path if combined_path.exists() else None

if __name__ == "__main__":
    print("=" * 50)
    print("ç»„åˆæ•°æ®å¤„ç†æ¨¡å—æµ‹è¯•")
    print("=" * 50)

    try:
        # æ‰§è¡Œæ•°æ®åˆå¹¶
        result_path = combine_data()

        # æ˜¾ç¤ºé¢„è§ˆ
        if result_path:
            display_combined_data_preview(result_path)

            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            df = pd.read_csv(result_path, encoding='utf-8-sig')
            required_cols = ['å¼€ç›˜ä»·', 'æ”¶ç›˜ä»·', 'MA20', 'MA50', 'RSI']
            missing_cols = [col for col in required_cols if col not in df.columns]

            if missing_cols:
                print(f"\nâš ï¸ è­¦å‘Š: ç¼ºå°‘å…³é”®åˆ— - {missing_cols}")
            else:
                print("\nâœ… æ•°æ®éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()