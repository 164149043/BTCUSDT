"""
DeepSeekæ¿€è¿›æ¨¡å¼ä¼˜åŒ–æœ€ç»ˆæŠ¥å‘Š
å±•ç¤ºæ‰€æœ‰ä¼˜åŒ–æˆæœå’Œä½¿ç”¨æŒ‡å—
"""

import pandas as pd
from pathlib import Path

DATA_DIR = Path('data')

def show_optimization_success():
    """æ˜¾ç¤ºä¼˜åŒ–æˆåŠŸéªŒè¯"""
    print("ğŸ‰ DeepSeekæ¿€è¿›æ¨¡å¼ä¼˜åŒ–æˆåŠŸéªŒè¯æŠ¥å‘Š")
    print("=" * 80)
    
    # æŸ¥æ‰¾æœ€æ–°çš„å®Œæ•´ç»„åˆæ•°æ®æ–‡ä»¶
    all_files = list(DATA_DIR.glob("*ç»„åˆæ•°æ®*.csv"))
    latest_files = [f for f in all_files if not f.name.endswith('_23col.csv')]
    
    if not latest_files:
        print("âŒ æœªæ‰¾åˆ°å®Œæ•´ç»„åˆæ•°æ®æ–‡ä»¶")
        return False
    
    latest_file = max(latest_files, key=lambda x: x.stat().st_mtime)
    
    try:
        df = pd.read_csv(latest_file, encoding='utf-8-sig')
        
        print(f"ğŸ“ éªŒè¯æ–‡ä»¶: {latest_file.name}")
        print(f"ğŸ“Š æ•°æ®è§„æ¨¡: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {latest_file.stat().st_size / 1024:.1f}KB")
        
        # éªŒè¯DeepSeekæ–°å¢æŒ‡æ ‡
        deepseek_indicators = {
            'MA3': 'è¶…çŸ­æœŸå‡çº¿ (3æœŸ)',
            'Volume_MA20': 'æˆäº¤é‡20æœŸå‡çº¿',
            'Volume_Ratio': 'æˆäº¤é‡æ¯”ç‡',
            'MA_Fast_Signal': 'å¿«é€ŸMAäº¤å‰ä¿¡å·',
            'MACD_Zero_Cross': 'MACDé›¶è½´äº¤å‰',
            'BB_Breakout_Strength': 'å¸ƒæ—å¸¦çªç ´å¼ºåº¦',
            'Fib_Key_Zone': 'æ–æ³¢é‚£å¥‘å…³é”®åŒºåŸŸ'
        }
        
        print(f"\nâœ… DeepSeekæ–°å¢æŒ‡æ ‡éªŒè¯ç»“æœ:")
        success_count = 0
        for indicator, description in deepseek_indicators.items():
            if indicator in df.columns:
                valid_count = df[indicator].notna().sum()
                success_rate = valid_count / len(df) * 100
                print(f"   âœ… {indicator} ({description})")
                print(f"      æœ‰æ•ˆæ•°æ®: {valid_count}/{len(df)} ({success_rate:.1f}%)")
                success_count += 1
                
                # æ˜¾ç¤ºæœ€æ–°å€¼ç¤ºä¾‹
                if valid_count > 0:
                    latest_value = df[indicator].iloc[-1]
                    if isinstance(latest_value, (int, float)):
                        print(f"      æœ€æ–°å€¼: {latest_value:.4f}")
                    else:
                        print(f"      æœ€æ–°å€¼: {latest_value}")
            else:
                print(f"   âŒ {indicator}: æœªæ‰¾åˆ°")
        
        print(f"\nğŸ¯ ä¼˜åŒ–æˆåŠŸç‡: {success_count}/{len(deepseek_indicators)} ({success_count/len(deepseek_indicators)*100:.1f}%)")
        
        return success_count == len(deepseek_indicators)
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False

def analyze_signal_improvements():
    """åˆ†æä¿¡å·æ”¹è¿›æ•ˆæœ"""
    print(f"\nğŸ“ˆ ä¿¡å·æ”¹è¿›æ•ˆæœåˆ†æ")
    print("=" * 80)
    
    # æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶
    all_files = list(DATA_DIR.glob("*ç»„åˆæ•°æ®*.csv"))
    latest_files = [f for f in all_files if not f.name.endswith('_23col.csv')]
    
    if not latest_files:
        return
    
    latest_file = max(latest_files, key=lambda x: x.stat().st_mtime)
    
    try:
        df = pd.read_csv(latest_file, encoding='utf-8-sig')
        
        # åˆ†æMA3å¿«é€Ÿä¿¡å·
        if 'MA_Fast_Signal' in df.columns:
            fast_signals = df['MA_Fast_Signal'].value_counts()
            print("âš¡ MA3å¿«é€Ÿä¿¡å·åˆ†æ:")
            for signal, count in fast_signals.items():
                percentage = count / len(df) * 100
                print(f"   {signal}: {count}æ¬¡ ({percentage:.1f}%)")
        
        # åˆ†æMACDé›¶è½´äº¤å‰
        if 'MACD_Zero_Cross' in df.columns:
            zero_cross_data = df[df['MACD_Zero_Cross'] != '']
            if len(zero_cross_data) > 0:
                print(f"\nğŸ¯ MACDé›¶è½´äº¤å‰åˆ†æ:")
                cross_types = zero_cross_data['MACD_Zero_Cross'].value_counts()
                for cross_type, count in cross_types.items():
                    print(f"   {cross_type}: {count}æ¬¡")
                print(f"   äº¤å‰é¢‘ç‡: {len(zero_cross_data)/len(df)*100:.1f}%")
            else:
                print(f"\nğŸ¯ MACDé›¶è½´äº¤å‰: å½“å‰å‘¨æœŸå†…æ— äº¤å‰")
        
        # åˆ†ææˆäº¤é‡ç¡®è®¤æ•ˆæœ
        if 'Volume_Ratio' in df.columns:
            high_volume = df[df['Volume_Ratio'] > 1.5]
            low_volume = df[df['Volume_Ratio'] < 0.8]
            normal_volume = df[(df['Volume_Ratio'] >= 0.8) & (df['Volume_Ratio'] <= 1.5)]
            
            print(f"\nğŸ“Š æˆäº¤é‡åˆ†å¸ƒä¼˜åŒ–:")
            print(f"   é«˜æˆäº¤é‡(>1.5å€): {len(high_volume)}æ¬¡ ({len(high_volume)/len(df)*100:.1f}%)")
            print(f"   æ­£å¸¸æˆäº¤é‡: {len(normal_volume)}æ¬¡ ({len(normal_volume)/len(df)*100:.1f}%)")
            print(f"   ä½æˆäº¤é‡(<0.8å€): {len(low_volume)}æ¬¡ ({len(low_volume)/len(df)*100:.1f}%)")
            
            if len(high_volume) > 0:
                avg_ratio = high_volume['Volume_Ratio'].mean()
                max_ratio = high_volume['Volume_Ratio'].max()
                print(f"   é«˜æˆäº¤é‡å¹³å‡å€æ•°: {avg_ratio:.2f}å€")
                print(f"   æœ€é«˜æˆäº¤é‡å€æ•°: {max_ratio:.2f}å€")
        
        # åˆ†æå¸ƒæ—å¸¦çªç ´å¼ºåº¦
        if 'BB_Breakout_Strength' in df.columns:
            breakout_data = df[df['BB_Breakout_Strength'] != '']
            if len(breakout_data) > 0:
                print(f"\nğŸ“ˆ å¸ƒæ—å¸¦çªç ´å¼ºåº¦:")
                breakout_types = breakout_data['BB_Breakout_Strength'].value_counts()
                for breakout_type, count in breakout_types.items():
                    print(f"   {breakout_type}: {count}æ¬¡")
            else:
                print(f"\nğŸ“ˆ å¸ƒæ—å¸¦çªç ´å¼ºåº¦: å½“å‰å‘¨æœŸå†…æ— å¸¦é‡çªç ´")
        
        # åˆ†ææ–æ³¢é‚£å¥‘å…³é”®åŒºåŸŸ
        if 'Fib_Key_Zone' in df.columns:
            fib_zones = df[df['Fib_Key_Zone'] != '']
            if len(fib_zones) > 0:
                print(f"\nğŸ”¢ æ–æ³¢é‚£å¥‘å…³é”®åŒºåŸŸ:")
                zone_types = fib_zones['Fib_Key_Zone'].value_counts()
                for zone_type, count in zone_types.items():
                    print(f"   {zone_type}: {count}æ¬¡")
                print(f"   å…³é”®åŒºåŸŸè¦†ç›–ç‡: {len(fib_zones)/len(df)*100:.1f}%")
            else:
                print(f"\nğŸ”¢ æ–æ³¢é‚£å¥‘å…³é”®åŒºåŸŸ: å½“å‰å‘¨æœŸå†…æ— å…³é”®åŒºåŸŸ")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")

def show_parameter_optimization():
    """æ˜¾ç¤ºå‚æ•°ä¼˜åŒ–æ•ˆæœ"""
    print(f"\nâš™ï¸ å‚æ•°æ¿€è¿›åŒ–ä¼˜åŒ–æ•ˆæœ")
    print("=" * 80)
    
    print("ğŸ¯ æ¿€è¿›æ¨¡å¼å‚æ•°è°ƒæ•´:")
    
    parameter_changes = {
        'MAç³»ç»Ÿä¼˜åŒ–': {
            'MA_SHORT_TERM': '20 â†’ 14 (ç¼©çŸ­30%)',
            'MA_LONG_TERM': '50 â†’ 35 (ç¼©çŸ­30%)',
            'æ–°å¢MA3': 'è¶…çŸ­æœŸå‡çº¿ï¼Œæ•æ‰æçŸ­æœŸè¶‹åŠ¿'
        },
        'MACDç³»ç»Ÿä¼˜åŒ–': {
            'MACD_FAST': '12 â†’ 8 (ç¼©çŸ­33%)',
            'MACD_SLOW': '26 â†’ 18 (ç¼©çŸ­31%)',
            'é›¶è½´äº¤å‰æ£€æµ‹': 'æ–°å¢è¶‹åŠ¿è½¬æ¢ç¡®è®¤ä¿¡å·'
        },
        'RSIç³»ç»Ÿä¼˜åŒ–': {
            'RSI_PERIOD': '14 â†’ 10 (ç¼©çŸ­29%)',
            'é˜ˆå€¼è°ƒæ•´': 'è¶…ä¹°80/è¶…å–20 (æ›´æ¿€è¿›)'
        },
        'å¸ƒæ—å¸¦ä¼˜åŒ–': {
            'BB_STD_DEV': '2.0 â†’ 3.0 (æ”¾å®½50%)',
            'çªç ´ç¡®è®¤': 'æ–°å¢æˆäº¤é‡ç¡®è®¤æœºåˆ¶'
        },
        'æˆäº¤é‡åˆ†æ': {
            'Volume_MA20': 'æ–°å¢æˆäº¤é‡å‡çº¿',
            'Volume_Ratio': 'æˆäº¤é‡æ¯”ç‡åˆ†æ',
            'é‡ä»·ç¡®è®¤': 'å¸¦é‡/ç¼©é‡ä¿¡å·æ ‡è®°'
        }
    }
    
    for category, changes in parameter_changes.items():
        print(f"\nğŸ“Š {category}:")
        for param, change in changes.items():
            print(f"   â€¢ {param}: {change}")

def show_usage_recommendations():
    """æ˜¾ç¤ºä½¿ç”¨å»ºè®®"""
    print(f"\nğŸ’¡ DeepSeekæ¿€è¿›æ¨¡å¼ä½¿ç”¨æŒ‡å—")
    print("=" * 80)
    
    print("ğŸ¯ æœ€ä½³é€‚ç”¨åœºæ™¯:")
    scenarios = [
        "æ—¥å†…äº¤æ˜“å’Œè¶…çŸ­çº¿æ“ä½œ (15åˆ†é’Ÿ-1å°æ—¶)",
        "é«˜æ³¢åŠ¨çš„åŠ å¯†è´§å¸å¸‚åœº",
        "éœ€è¦å¿«é€Ÿè¿›å‡ºåœºçš„ç­–ç•¥",
        "è¿½æ±‚æ›´æ•æ„Ÿäº¤æ˜“ä¿¡å·çš„åœºæ™¯",
        "ä¸“ä¸šäº¤æ˜“è€…çš„é«˜é¢‘æ“ä½œ"
    ]
    
    for scenario in scenarios:
        print(f"   â€¢ {scenario}")
    
    print(f"\nğŸ”¥ é‡ç‚¹å…³æ³¨ä¿¡å·:")
    key_signals = [
        "ğŸ”¥è¶…å¼ºçœ‹æ¶¨/çœ‹è·Œ: å¤šæŒ‡æ ‡ååŒç¡®è®¤çš„æœ€å¼ºä¿¡å·",
        "MA3å¿«é€Ÿé‡‘å‰/æ­»å‰: è¶…çŸ­æœŸè¶‹åŠ¿å˜åŒ–",
        "MACDé›¶è½´ä¸Šç©¿/ä¸‹ç©¿: è¶‹åŠ¿è½¬æ¢ç¡®è®¤",
        "å¸¦é‡çªç ´ä¸Šè½¨/ä¸‹è½¨: æˆäº¤é‡ç¡®è®¤çš„çªç ´",
        "æ–æ³¢é‚£å¥‘å…³é”®åŒºåŸŸ: ç²¾ç¡®çš„æ”¯æ’‘é˜»åŠ›ä½"
    ]
    
    for signal in key_signals:
        print(f"   â€¢ {signal}")
    
    print(f"\nâš ï¸ é£é™©ç®¡ç†å»ºè®®:")
    risk_tips = [
        "æ¿€è¿›æ¨¡å¼ä¿¡å·æ›´é¢‘ç¹ï¼Œéœ€è¦ä¸¥æ ¼çš„æ­¢æŸç­–ç•¥",
        "é‡ç‚¹å…³æ³¨ğŸ”¥è¶…å¼ºä¿¡å·ï¼Œè¿‡æ»¤ä¸€èˆ¬ä¿¡å·",
        "ç»“åˆæˆäº¤é‡ç¡®è®¤æé«˜ä¿¡å·è´¨é‡",
        "åœ¨é«˜æ³¢åŠ¨å¸‚åœºä¸­æ•ˆæœæ›´ä½³",
        "å»ºè®®æœ‰ç»éªŒçš„äº¤æ˜“è€…ä½¿ç”¨",
        "é¿å…æƒ…ç»ªåŒ–äº¤æ˜“ï¼Œä¸¥æ ¼æ‰§è¡Œç­–ç•¥"
    ]
    
    for tip in risk_tips:
        print(f"   â€¢ {tip}")

def show_file_recommendations():
    """æ˜¾ç¤ºæ–‡ä»¶ä½¿ç”¨å»ºè®®"""
    print(f"\nğŸ“ æ–‡ä»¶ä½¿ç”¨å»ºè®®")
    print("=" * 80)
    
    # æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
    files_info = {
        'å®Œæ•´ç»„åˆæ•°æ®': {
            'pattern': '*ç»„åˆæ•°æ®_*.csv',
            'exclude': '_23col.csv',
            'description': 'åŒ…å«56ä¸ªæŒ‡æ ‡çš„å®Œæ•´æ•°æ®',
            'usage': 'æ·±åº¦æŠ€æœ¯åˆ†æï¼Œä¸“ä¸šäº¤æ˜“è€…ä½¿ç”¨'
        },
        '23åˆ—ç²¾ç®€æ•°æ®': {
            'pattern': '*_23col.csv',
            'exclude': None,
            'description': 'ç”¨æˆ·æŒ‡å®šçš„23ä¸ªæ ¸å¿ƒæŒ‡æ ‡',
            'usage': 'DeepSeek AIåˆ†æï¼Œå¿«é€Ÿå†³ç­–'
        },
        'äº¤æ˜“åˆ†ææŠ¥å‘Š': {
            'pattern': '*äº¤æ˜“åˆ†ææŠ¥å‘Š*.txt',
            'exclude': None,
            'description': 'ç»“æ„åŒ–çš„äº¤æ˜“å»ºè®®',
            'usage': 'AIå¯¹è¯åˆ†æï¼Œç­–ç•¥å‚è€ƒ'
        }
    }
    
    for file_type, info in files_info.items():
        files = list(DATA_DIR.glob(info['pattern']))
        if info['exclude']:
            files = [f for f in files if info['exclude'] not in f.name]
        
        if files:
            latest_file = max(files, key=lambda x: x.stat().st_mtime)
            size_kb = latest_file.stat().st_size / 1024
            
            print(f"\nğŸ“Š {file_type}:")
            print(f"   æ–‡ä»¶: {latest_file.name}")
            print(f"   å¤§å°: {size_kb:.1f}KB")
            print(f"   è¯´æ˜: {info['description']}")
            print(f"   ç”¨é€”: {info['usage']}")

def main():
    """ä¸»å‡½æ•°"""
    print("DeepSeekæ¿€è¿›æ¨¡å¼ä¼˜åŒ–æœ€ç»ˆæŠ¥å‘Š")
    print("=" * 80)
    print("ta_calculator.py DeepSeekä¼˜åŒ–ä»£ç åº”ç”¨æˆæœ")
    print("=" * 80)
    
    # 1. æ˜¾ç¤ºä¼˜åŒ–æˆåŠŸéªŒè¯
    success = show_optimization_success()
    
    if success:
        # 2. åˆ†æä¿¡å·æ”¹è¿›æ•ˆæœ
        analyze_signal_improvements()
        
        # 3. æ˜¾ç¤ºå‚æ•°ä¼˜åŒ–
        show_parameter_optimization()
        
        # 4. æ˜¾ç¤ºä½¿ç”¨å»ºè®®
        show_usage_recommendations()
        
        # 5. æ˜¾ç¤ºæ–‡ä»¶å»ºè®®
        show_file_recommendations()
        
        print(f"\n" + "=" * 80)
        print("ğŸ‰ DeepSeekæ¿€è¿›æ¨¡å¼ä¼˜åŒ–å®Œå…¨æˆåŠŸ!")
        print("âœ… 7ä¸ªæ–°å¢æŒ‡æ ‡å…¨éƒ¨éªŒè¯é€šè¿‡")
        print("âœ… å‚æ•°æ¿€è¿›åŒ–ä¼˜åŒ–å·²ç”Ÿæ•ˆ")
        print("âœ… ä¿¡å·å¢å¼ºç³»ç»Ÿå·²æ¿€æ´»")
        print("âœ… æˆäº¤é‡ç¡®è®¤æœºåˆ¶å·²å¯ç”¨")
        print("âœ… æ–æ³¢é‚£å¥‘åˆ†æå·²å¢å¼º")
        
        print(f"\nğŸš€ ç³»ç»Ÿç°åœ¨å…·å¤‡:")
        print("   â€¢ æ›´æ•æ„Ÿçš„æŠ€æœ¯æŒ‡æ ‡å‚æ•°")
        print("   â€¢ è¶…çŸ­æœŸMA3è¶‹åŠ¿æ•æ‰")
        print("   â€¢ MACDé›¶è½´äº¤å‰ç¡®è®¤")
        print("   â€¢ æˆäº¤é‡é‡ä»·ç¡®è®¤")
        print("   â€¢ ğŸ”¥è¶…å¼ºä¿¡å·å¤šæŒ‡æ ‡ååŒ")
        print("   â€¢ ç²¾ç¡®çš„æ–æ³¢é‚£å¥‘å…³é”®åŒºåŸŸ")
        
        print(f"\nğŸ’ ç‰¹åˆ«é€‚åˆ:")
        print("   â€¢ 15åˆ†é’Ÿçº¿æ—¥å†…äº¤æ˜“")
        print("   â€¢ 1å°æ—¶çº¿çŸ­çº¿æ“ä½œ")
        print("   â€¢ é«˜æ³¢åŠ¨å¸‚åœºç¯å¢ƒ")
        print("   â€¢ ä¸“ä¸šäº¤æ˜“è€…ä½¿ç”¨")
        
    else:
        print("\nâŒ éƒ¨åˆ†ä¼˜åŒ–æœªå®Œå…¨ç”Ÿæ•ˆï¼Œè¯·æ£€æŸ¥ä»£ç å®ç°")

if __name__ == "__main__":
    main()
